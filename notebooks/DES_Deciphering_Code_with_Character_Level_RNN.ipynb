{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GSMwZnsd1-u"
   },
   "source": [
    "# Deciphering Code with Character-Level RNN\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOHhumaPBdAk"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passwords</th>\n",
       "      <th>ciphertext</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2428031609</td>\n",
       "      <td>6960043906fcfa4152225d4cbeed92c9</td>\n",
       "      <td>C5SZWCOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4531040045</td>\n",
       "      <td>bdbffdd0a1df14090eec745de30a3c0b</td>\n",
       "      <td>KFD7SI1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almigrana1</td>\n",
       "      <td>ad65ac507a1184ceb9a42afc48482a9f</td>\n",
       "      <td>KFD7SI1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quiero95</td>\n",
       "      <td>8b812dcbced662658507d26dfea58f83</td>\n",
       "      <td>CFJT97ZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doitnow2</td>\n",
       "      <td>590c4cce603fc18346b266f4d0805116</td>\n",
       "      <td>40H2ETAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>dime168</td>\n",
       "      <td>b0e07c1a6af86c4c</td>\n",
       "      <td>Q0GM6RKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>!l0v3k3v!n</td>\n",
       "      <td>45820d4b54019ec2eca8361c510392d3</td>\n",
       "      <td>1V3YX0JE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>9870tmf05</td>\n",
       "      <td>f8a9a57f8b5e5843c94911676c7151f3</td>\n",
       "      <td>KFD7SI1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>CAMILA</td>\n",
       "      <td>cceedf72faf67106</td>\n",
       "      <td>Y7HFVYA2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>caren14</td>\n",
       "      <td>2947f0675fd2bad2</td>\n",
       "      <td>Y7HFVYA2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Passwords                        ciphertext       key\n",
       "0       2428031609  6960043906fcfa4152225d4cbeed92c9  C5SZWCOV\n",
       "1       4531040045  bdbffdd0a1df14090eec745de30a3c0b  KFD7SI1Q\n",
       "2       almigrana1  ad65ac507a1184ceb9a42afc48482a9f  KFD7SI1Q\n",
       "3         quiero95  8b812dcbced662658507d26dfea58f83  CFJT97ZI\n",
       "4         doitnow2  590c4cce603fc18346b266f4d0805116  40H2ETAQ\n",
       "...            ...                               ...       ...\n",
       "199995     dime168                  b0e07c1a6af86c4c  Q0GM6RKL\n",
       "199996  !l0v3k3v!n  45820d4b54019ec2eca8361c510392d3  1V3YX0JE\n",
       "199997   9870tmf05  f8a9a57f8b5e5843c94911676c7151f3  KFD7SI1Q\n",
       "199998      CAMILA                  cceedf72faf67106  Y7HFVYA2\n",
       "199999     caren14                  2947f0675fd2bad2  Y7HFVYA2\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/DES.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()[:120000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passwords</th>\n",
       "      <th>ciphertext</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2428031609</td>\n",
       "      <td>6960043906fcfa4152225d4cbeed92c9</td>\n",
       "      <td>C5SZWCOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4531040045</td>\n",
       "      <td>bdbffdd0a1df14090eec745de30a3c0b</td>\n",
       "      <td>KFD7SI1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almigrana1</td>\n",
       "      <td>ad65ac507a1184ceb9a42afc48482a9f</td>\n",
       "      <td>KFD7SI1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quiero95</td>\n",
       "      <td>8b812dcbced662658507d26dfea58f83</td>\n",
       "      <td>CFJT97ZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doitnow2</td>\n",
       "      <td>590c4cce603fc18346b266f4d0805116</td>\n",
       "      <td>40H2ETAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>quaisha123</td>\n",
       "      <td>d012832807eaebe80d91c997ca446d81</td>\n",
       "      <td>MJCUSM1E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>7192qween</td>\n",
       "      <td>e793cefe998b96d39caff619365f8d83</td>\n",
       "      <td>6BGZVHUW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>janet35</td>\n",
       "      <td>30b95f40bae432ee</td>\n",
       "      <td>Q0GM6RKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>velly</td>\n",
       "      <td>e30bb04382af7994</td>\n",
       "      <td>Y7HFVYA2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>almaenid28</td>\n",
       "      <td>01db7a643f6c56c924c9c3a2276a15d4</td>\n",
       "      <td>QOM4GEGJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Passwords                        ciphertext       key\n",
       "0       2428031609  6960043906fcfa4152225d4cbeed92c9  C5SZWCOV\n",
       "1       4531040045  bdbffdd0a1df14090eec745de30a3c0b  KFD7SI1Q\n",
       "2       almigrana1  ad65ac507a1184ceb9a42afc48482a9f  KFD7SI1Q\n",
       "3         quiero95  8b812dcbced662658507d26dfea58f83  CFJT97ZI\n",
       "4         doitnow2  590c4cce603fc18346b266f4d0805116  40H2ETAQ\n",
       "...            ...                               ...       ...\n",
       "119995  quaisha123  d012832807eaebe80d91c997ca446d81  MJCUSM1E\n",
       "119996   7192qween  e793cefe998b96d39caff619365f8d83  6BGZVHUW\n",
       "119997     janet35                  30b95f40bae432ee  Q0GM6RKL\n",
       "119998       velly                  e30bb04382af7994  Y7HFVYA2\n",
       "119999  almaenid28  01db7a643f6c56c924c9c3a2276a15d4  QOM4GEGJ\n",
       "\n",
       "[120000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'].apply(str)\n",
    "df['ciphertext'].apply(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44T02G-FBNYf"
   },
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9b4vwned1-4",
    "outputId": "a955da71-52ac-4881-e8ed-78d398c47ec9"
   },
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level=True)\n",
    "    x_tk.fit_on_texts(x)                 \n",
    "\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    \n",
    "    return pad_sequences(x, maxlen=length, padding=\"post\", truncating=\"post\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdV69c9gd1-5"
   },
   "source": [
    "### Preprocess Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxTxyzCHd1-5",
    "outputId": "3f358e66-7cca-4959-8f96-5b96b818532f"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n"
     ]
    }
   ],
   "source": [
    "preproc_code_sentences, preproc_plaintext_sentences, code_tokenizer, plaintext_tokenizer = preprocess(df['Passwords'], df['ciphertext'])\n",
    "\n",
    "print('Data Preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NlbiDf-d1-6",
    "outputId": "21c9cb2e-025e-4032-e29b-8d5a36a6cd4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 17,  7, 15,  5, 13,  3, 19,  5, 12,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_code_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrK0B3ttd1-6",
    "outputId": "86b2b875-ef69-4f0b-f245-62dbf0d7bb3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRkiK6Qjd1-6",
    "outputId": "a473c0bf-f76d-4689-8884-028a871751b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plaintext_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hk8HcQtEd1-7",
    "outputId": "e734311c-c349-47d9-c726-ff275f434840"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5': 1,\n",
       " 'd': 2,\n",
       " 'c': 3,\n",
       " '0': 4,\n",
       " '9': 5,\n",
       " '4': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '3': 9,\n",
       " 'e': 10,\n",
       " '1': 11,\n",
       " 'b': 12,\n",
       " 'a': 13,\n",
       " 'f': 14,\n",
       " '8': 15,\n",
       " '2': 16}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plaintext_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPevgp-id1-7",
    "outputId": "e7085fd4-de9d-4636-a167-3681e52eb0a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 255)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_code_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxFxFP-Bd1-7",
    "outputId": "f2ae4663-bf7d-4992-ebad-54c974e2b78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 528, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_plaintext_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKHZqlXyd1-8"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HnLsrRNZd1-8"
   },
   "outputs": [],
   "source": [
    "from keras.layers import GRU, Input, Dense, TimeDistributed, RNN, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "def simple_model(input_shape, output_sequence_length, code_vocab_size, plaintext_vocab_size):\n",
    "    x = Input(shape=input_shape[1:])   \n",
    "    seq = LSTM(units= 256, return_sequences = True, activation=\"tanh\", name='Layer1')(x)\n",
    "    output = TimeDistributed(Dense(units = plaintext_vocab_size, activation='softmax', name='Layer2'))(seq)\n",
    "    model = Model(inputs = x, outputs = output)\n",
    "    model.compile(optimizer='adam', loss= sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "tmp_x = pad(preproc_code_sentences, preproc_plaintext_sentences.shape[1]) \n",
    "tmp_x = tmp_x.reshape((-1, preproc_plaintext_sentences.shape[-2], 1))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOCnrOcnd1-8",
    "outputId": "e9ed1e68-9923-49c0-fe27-7fc6040b24cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 528, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBuB49pZd1-9",
    "outputId": "5e165d21-0165-42bb-c5e2-e9bad83454ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 528, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Layer1 (LSTM)                (None, 528, 256)          264192    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 528, 17)           4369      \n",
      "=================================================================\n",
      "Total params: 268,561\n",
      "Trainable params: 268,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_plaintext_sentences.shape[1],\n",
    "    len(code_tokenizer.word_index)+1,\n",
    "    len(plaintext_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1mw5FFZd1-9",
    "outputId": "fa187ab0-36f6-4793-b770-6e678781cacb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 528, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model.get_layer(name=\"Layer1\").output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGK61DACd1-9",
    "outputId": "6059e2f6-bcf3-4b3a-c4c0-81656b9a336f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1313/1313 [==============================] - 106s 68ms/step - loss: 0.3146 - accuracy: 0.9366 - val_loss: 0.1466 - val_accuracy: 0.9516\n",
      "Epoch 2/15\n",
      "1313/1313 [==============================] - 90s 69ms/step - loss: 0.1471 - accuracy: 0.9516 - val_loss: 0.1440 - val_accuracy: 0.9517\n",
      "Epoch 3/15\n",
      "1313/1313 [==============================] - 90s 69ms/step - loss: 0.1441 - accuracy: 0.9518 - val_loss: 0.1429 - val_accuracy: 0.9519\n",
      "Epoch 4/15\n",
      "1313/1313 [==============================] - 91s 69ms/step - loss: 0.1438 - accuracy: 0.9519 - val_loss: 0.1430 - val_accuracy: 0.9518\n",
      "Epoch 5/15\n",
      "1313/1313 [==============================] - 91s 69ms/step - loss: 0.1438 - accuracy: 0.9518 - val_loss: 0.1428 - val_accuracy: 0.9518\n",
      "Epoch 6/15\n",
      "1313/1313 [==============================] - 91s 69ms/step - loss: 0.1433 - accuracy: 0.9518 - val_loss: 0.1428 - val_accuracy: 0.9519\n",
      "Epoch 7/15\n",
      "1313/1313 [==============================] - 91s 69ms/step - loss: 0.1437 - accuracy: 0.9518 - val_loss: 0.1437 - val_accuracy: 0.9518\n",
      "Epoch 8/15\n",
      "1313/1313 [==============================] - 90s 68ms/step - loss: 0.1429 - accuracy: 0.9519 - val_loss: 0.1426 - val_accuracy: 0.9519\n",
      "Epoch 9/15\n",
      "1313/1313 [==============================] - 90s 68ms/step - loss: 0.1426 - accuracy: 0.9519 - val_loss: 0.1428 - val_accuracy: 0.9518\n",
      "Epoch 10/15\n",
      "1313/1313 [==============================] - 90s 68ms/step - loss: 0.1423 - accuracy: 0.9520 - val_loss: 0.1425 - val_accuracy: 0.9519\n",
      "Epoch 11/15\n",
      "1313/1313 [==============================] - 90s 68ms/step - loss: 0.1426 - accuracy: 0.9519 - val_loss: 0.1425 - val_accuracy: 0.9518\n",
      "Epoch 12/15\n",
      "1313/1313 [==============================] - 90s 69ms/step - loss: 0.1424 - accuracy: 0.9519 - val_loss: 0.1425 - val_accuracy: 0.9518\n",
      "Epoch 13/15\n",
      "1313/1313 [==============================] - 90s 69ms/step - loss: 0.1425 - accuracy: 0.9519 - val_loss: 0.1427 - val_accuracy: 0.9519\n",
      "Epoch 14/15\n",
      "1313/1313 [==============================] - 90s 69ms/step - loss: 0.1425 - accuracy: 0.9519 - val_loss: 0.1426 - val_accuracy: 0.9518\n",
      "Epoch 15/15\n",
      "1313/1313 [==============================] - 90s 69ms/step - loss: 0.1427 - accuracy: 0.9519 - val_loss: 0.1425 - val_accuracy: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c24727af40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model.fit(tmp_x, preproc_plaintext_sentences, batch_size=64, epochs=15, validation_split=0.3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PI9Ypxpd1--",
    "outputId": "18741fa3-e00d-469a-88aa-bb6944e808e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e d 2 e e 0 0 0 c 0 c b 9 9 e e 2 2 2 2 2 2 2 2 c c c c 8 8 3 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], plaintext_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1JG7ZGkhd1--",
    "outputId": "e27e98ad-a65e-4593-ebdd-302e859ce580"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428031609'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF4h-TUXd1-_"
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zr9DVkOTd1-_"
   },
   "outputs": [],
   "source": [
    "def simple_model1(input_shape, output_sequence_length, code_vocab_size, plaintext_vocab_size):\n",
    "    x = Input(shape=input_shape[1:])   \n",
    "    seq = GRU(units= 256, return_sequences = True, activation=\"tanh\", name='Layer1')(x)  # output must be batchsize x timesteps x units\n",
    "    output = TimeDistributed(Dense(units = plaintext_vocab_size, activation='softmax', name='Layer2'))(seq)\n",
    "    model = Model(inputs = x, outputs = output)\n",
    "    model.compile(optimizer='adam', loss= sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nv3fRkj7d1-_",
    "outputId": "ac22d596-80eb-4d0e-9cfc-090be796cf81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 528, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Layer1 (GRU)                 (None, 528, 256)          198912    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 528, 17)           4369      \n",
      "=================================================================\n",
      "Total params: 203,281\n",
      "Trainable params: 203,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model1 = simple_model1(\n",
    "    tmp_x.shape,\n",
    "    preproc_plaintext_sentences.shape[1],\n",
    "    len(code_tokenizer.word_index)+1,\n",
    "    len(plaintext_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVg9KJaad1-_",
    "outputId": "4df6502d-ca0c-42df-869e-89859ed38db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1313/1313 [==============================] - 77s 57ms/step - loss: 0.2834 - accuracy: 0.9498 - val_loss: 0.1619 - val_accuracy: 0.9506ETA: 55s - loss - ETA: 53s - l - ETA: 42s - l - ETA: 39s - loss - ETA: 37s - loss: 0.4051  - ETA: 35s - loss: 0.3940 - accura - ETA: 30s - loss: 0.3661 - accuracy: 0.949 - ETA: 30s - loss: 0.3657 - accuracy: - ETA: 29s - loss: 0 - ETA: 27s - ETA: 6s - loss: 0.2945 - accura - ETA: 6s - loss: 0.2936 - accuracy: 0. - ETA: 5s - loss: 0.2933 - accura - ETA: 5s - loss: 0.2924 - accuracy: 0.94 - ETA: 5s - loss: - ETA: 1s - loss: 0.2866 - accuracy: 0. - E\n",
      "Epoch 2/15\n",
      "1313/1313 [==============================] - 75s 57ms/step - loss: 0.1595 - accuracy: 0.9508 - val_loss: 0.1506 - val_accuracy: 0.9512: 0.1608 - accuracy - ETA: 4 - ETA: 40s - loss: 0.1607 - accur - ETA: 39s - loss: 0.1607 -  - ETA: 38s - loss: 0. - ETA: 36s - loss: 0.1606 - accuracy - ETA: 35s - loss: 0.1606 - accur - ETA: 34s - loss: 0.1605 - ac - ETA: 33s - lo - ETA: 30s - loss - ETA: 28s - l - ETA: 21s - loss: 0.1601 - accuracy: 0. - ETA:  - ETA: 17s - loss: 0.1600 - accuracy: 0.95 - ETA: 17s - loss: 0.1600 - accuracy: - ETA: 17s - loss: 0.16 - ETA: 15s - loss: 0.1600 - accuracy: 0. - ETA: 14s - loss: 0.1599 -  - ETA: 13s - loss: 0.1599 - accurac - ETA: 12s - loss: 0.1599 - accuracy: 0.95 - ETA: 12s - loss: 0.1 - ETA: 5s -\n",
      "Epoch 3/15\n",
      "1313/1313 [==============================] - 74s 57ms/step - loss: 0.1495 - accuracy: 0.9514 - val_loss: 0.1445 - val_accuracy: 0.9517A: 24s - loss: 0.1504 - - ETA: 23s - loss: 0.1504 - accurac - \n",
      "Epoch 4/15\n",
      "1313/1313 [==============================] - 76s 58ms/step - loss: 0.1629 - accuracy: 0.9503 - val_loss: 0.1632 - val_accuracy: 0.9507\n",
      "Epoch 5/15\n",
      "1313/1313 [==============================] - 75s 57ms/step - loss: 0.1623 - accuracy: 0.9508 - val_loss: 0.1597 - val_accuracy: 0.95072s - loss: 0.1624 - accuracy - ETA: 1s - l - ETA: 0s - loss: 0.1623 - \n",
      "Epoch 6/15\n",
      "1313/1313 [==============================] - 75s 57ms/step - loss: 0.1583 - accuracy: 0.9508 - val_loss: 0.1542 - val_accuracy: 0.9510\n",
      "Epoch 7/15\n",
      "1313/1313 [==============================] - 75s 57ms/step - loss: 0.1521 - accuracy: 0.9513 - val_loss: 0.1492 - val_accuracy: 0.9515s - los\n",
      "Epoch 8/15\n",
      "1313/1313 [==============================] - 76s 58ms/step - loss: 0.1469 - accuracy: 0.9517 - val_loss: 0.1445 - val_accuracy: 0.9518\n",
      "Epoch 9/15\n",
      "1313/1313 [==============================] - 76s 58ms/step - loss: 0.1444 - accuracy: 0.9518 - val_loss: 0.1435 - val_accuracy: 0.9518ss: 0.1441 - accuracy: 0. - ETA: 49s - lo\n",
      "Epoch 10/15\n",
      "1313/1313 [==============================] - 75s 57ms/step - loss: 0.1440 - accuracy: 0.9518 - val_loss: 0.1434 - val_accuracy: 0.9518\n",
      "Epoch 11/15\n",
      "1313/1313 [==============================] - 75s 57ms/step - loss: 0.1443 - accuracy: 0.9518 - val_loss: 0.1430 - val_accuracy: 0.9518ss: 0.1443 - accurac - ETA: 12s - l\n",
      "Epoch 12/15\n",
      "1313/1313 [==============================] - 75s 57ms/step - loss: 0.1457 - accuracy: 0.9516 - val_loss: 0.1441 - val_accuracy: 0.9518\n",
      "Epoch 13/15\n",
      "1313/1313 [==============================] - 76s 58ms/step - loss: 0.1471 - accuracy: 0.9516 - val_loss: 0.1448 - val_accuracy: 0.9518\n",
      "Epoch 14/15\n",
      "1313/1313 [==============================] - 75s 57ms/step - loss: 0.1434 - accuracy: 0.9518 - val_loss: 0.1430 - val_accuracy: 0.9518\n",
      "Epoch 15/15\n",
      "1313/1313 [==============================] - 75s 57ms/step - loss: 0.1435 - accuracy: 0.9518 - val_loss: 0.1431 - val_accuracy: 0.9518 54s - loss: 0.14 - ETA: 52s - loss: 0.1437 - accuracy: 0 - ETA: 51s - ETA: 0s - loss: 0.143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c27a89f310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model1.fit(tmp_x, preproc_plaintext_sentences, batch_size=64, epochs=15, validation_split=0.3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sr0zJux1d1-_",
    "outputId": "54ac6118-4a93-4968-f8c8-1dd9a11f76f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3 f 3 c f 3 b b b 3 3 b b b b b b b 0 d 7 7 7 7 7 7 7 2 2 2 c <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(logits_to_text(simple_rnn_model1.predict(tmp_x[:1])[0], plaintext_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fFQT3peGUOHg",
    "outputId": "659da06c-0ebb-44cf-ec44-6f90d7fc0379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428031609'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHjZkjOzd1_A"
   },
   "source": [
    "# SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "baVCVerFd1_A"
   },
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN \n",
    "def simple_model2(input_shape, output_sequence_length, code_vocab_size, plaintext_vocab_size):\n",
    "    x = Input(shape=input_shape[1:])      \n",
    "    seq = SimpleRNN(units= 256, return_sequences = True, activation=\"tanh\", name='Layer1')(x)   \n",
    "    output = TimeDistributed(Dense(units = plaintext_vocab_size, activation='softmax', name='Layer2'))(seq)    \n",
    "    model = Model(inputs = x, outputs = output)    \n",
    "    model.compile(optimizer='adam', loss= sparse_categorical_crossentropy, metrics=['accuracy'])    \n",
    "    model.summary()    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yieRDWbzd1_A",
    "outputId": "0db4c447-20c1-4589-f29d-150d755c913c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 528, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Layer1 (SimpleRNN)           (None, 528, 256)          66048     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 528, 17)           4369      \n",
      "=================================================================\n",
      "Total params: 70,417\n",
      "Trainable params: 70,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model2 = simple_model2(\n",
    "    tmp_x.shape,\n",
    "    preproc_plaintext_sentences.shape[1],\n",
    "    len(code_tokenizer.word_index)+1,\n",
    "    len(plaintext_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbr40u5Gd1_A",
    "outputId": "227f6ecf-3795-46ee-85d7-04ced2d0c98b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1313/1313 [==============================] - 383s 292ms/step - loss: 0.2804 - accuracy: 0.9491 - val_loss: 0.2911 - val_accuracy: 0.9495\n",
      "Epoch 2/5\n",
      "1313/1313 [==============================] - 382s 291ms/step - loss: 0.4911 - accuracy: 0.9301 - val_loss: 0.2063 - val_accuracy: 0.9499\n",
      "Epoch 3/5\n",
      "1313/1313 [==============================] - 384s 292ms/step - loss: 0.1729 - accuracy: 0.9503 - val_loss: 0.1654 - val_accuracy: 0.9505\n",
      "Epoch 4/5\n",
      "1313/1313 [==============================] - 385s 293ms/step - loss: 0.1652 - accuracy: 0.9505 - val_loss: 0.1648 - val_accuracy: 0.9506\n",
      "Epoch 5/5\n",
      "1313/1313 [==============================] - 391s 298ms/step - loss: 0.1689 - accuracy: 0.9504 - val_loss: 0.1692 - val_accuracy: 0.9499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c34920f910>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model2.fit(tmp_x, preproc_plaintext_sentences, batch_size=64, epochs=5, validation_split=0.3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYddd_hgd1_A",
    "outputId": "e20b6799-3560-4480-a15d-a356d76bd72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 9 8 1 b c a 5 d 2 b 0 3 f 6 0 a 1 8 9 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(logits_to_text(simple_rnn_model2.predict(tmp_x[:1])[0], plaintext_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FOpT4aQHUsbA",
    "outputId": "6a111a74-a67e-42bb-eaa0-1c0b7f77c749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428031609'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deciphering Code with Character-Level RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
