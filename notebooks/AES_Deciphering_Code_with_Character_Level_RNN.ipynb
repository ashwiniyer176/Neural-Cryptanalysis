{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GSMwZnsd1-u"
   },
   "source": [
    "# Deciphering Code with Character-Level RNN\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOHhumaPBdAk"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passwords</th>\n",
       "      <th>ciphertext</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2428031609</td>\n",
       "      <td>b'1092675125059b44fa88'</td>\n",
       "      <td>ZDBQ7O9F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4531040045</td>\n",
       "      <td>b'1e26ffabe380c3d0c299'</td>\n",
       "      <td>NO9EDSU0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almigrana1</td>\n",
       "      <td>b'2259ed1d208cca75004d'</td>\n",
       "      <td>4XS7R110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quiero95</td>\n",
       "      <td>b'16194b66fbca0eee'</td>\n",
       "      <td>BMZPZLBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doitnow2</td>\n",
       "      <td>b'fab56cb16f5cd504'</td>\n",
       "      <td>19RM3TPZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>dime168</td>\n",
       "      <td>b'ee2b9cf4479a64'</td>\n",
       "      <td>E68PIJK0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>!l0v3k3v!n</td>\n",
       "      <td>b'e56a59f153590322ed74'</td>\n",
       "      <td>REKBYL0P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>9870tmf05</td>\n",
       "      <td>b'0faaf9b73bc5bc9940'</td>\n",
       "      <td>3QJZBLJP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>CAMILA</td>\n",
       "      <td>b'a451626f19cb'</td>\n",
       "      <td>SOMFMV7Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>caren14</td>\n",
       "      <td>b'2054f21129cf9f'</td>\n",
       "      <td>4XS7R110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Passwords               ciphertext       key\n",
       "0       2428031609  b'1092675125059b44fa88'  ZDBQ7O9F\n",
       "1       4531040045  b'1e26ffabe380c3d0c299'  NO9EDSU0\n",
       "2       almigrana1  b'2259ed1d208cca75004d'  4XS7R110\n",
       "3         quiero95      b'16194b66fbca0eee'  BMZPZLBH\n",
       "4         doitnow2      b'fab56cb16f5cd504'  19RM3TPZ\n",
       "...            ...                      ...       ...\n",
       "199995     dime168        b'ee2b9cf4479a64'  E68PIJK0\n",
       "199996  !l0v3k3v!n  b'e56a59f153590322ed74'  REKBYL0P\n",
       "199997   9870tmf05    b'0faaf9b73bc5bc9940'  3QJZBLJP\n",
       "199998      CAMILA          b'a451626f19cb'  SOMFMV7Q\n",
       "199999     caren14        b'2054f21129cf9f'  4XS7R110\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/AES.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passwords</th>\n",
       "      <th>ciphertext</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2428031609</td>\n",
       "      <td>1092675125059b44fa88</td>\n",
       "      <td>ZDBQ7O9F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4531040045</td>\n",
       "      <td>1e26ffabe380c3d0c299</td>\n",
       "      <td>NO9EDSU0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almigrana1</td>\n",
       "      <td>2259ed1d208cca75004d</td>\n",
       "      <td>4XS7R110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quiero95</td>\n",
       "      <td>16194b66fbca0eee</td>\n",
       "      <td>BMZPZLBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doitnow2</td>\n",
       "      <td>fab56cb16f5cd504</td>\n",
       "      <td>19RM3TPZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>dime168</td>\n",
       "      <td>ee2b9cf4479a64</td>\n",
       "      <td>E68PIJK0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>!l0v3k3v!n</td>\n",
       "      <td>e56a59f153590322ed74</td>\n",
       "      <td>REKBYL0P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>9870tmf05</td>\n",
       "      <td>0faaf9b73bc5bc9940</td>\n",
       "      <td>3QJZBLJP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>CAMILA</td>\n",
       "      <td>a451626f19cb</td>\n",
       "      <td>SOMFMV7Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>caren14</td>\n",
       "      <td>2054f21129cf9f</td>\n",
       "      <td>4XS7R110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Passwords            ciphertext       key\n",
       "0       2428031609  1092675125059b44fa88  ZDBQ7O9F\n",
       "1       4531040045  1e26ffabe380c3d0c299  NO9EDSU0\n",
       "2       almigrana1  2259ed1d208cca75004d  4XS7R110\n",
       "3         quiero95      16194b66fbca0eee  BMZPZLBH\n",
       "4         doitnow2      fab56cb16f5cd504  19RM3TPZ\n",
       "...            ...                   ...       ...\n",
       "199995     dime168        ee2b9cf4479a64  E68PIJK0\n",
       "199996  !l0v3k3v!n  e56a59f153590322ed74  REKBYL0P\n",
       "199997   9870tmf05    0faaf9b73bc5bc9940  3QJZBLJP\n",
       "199998      CAMILA          a451626f19cb  SOMFMV7Q\n",
       "199999     caren14        2054f21129cf9f  4XS7R110\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeExtra(x):\n",
    "    x = x[2:-1]\n",
    "    return x\n",
    "\n",
    "df['ciphertext'] = df['ciphertext'].apply(lambda x: removeExtra(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()[:120000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passwords</th>\n",
       "      <th>ciphertext</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2428031609</td>\n",
       "      <td>1092675125059b44fa88</td>\n",
       "      <td>ZDBQ7O9F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4531040045</td>\n",
       "      <td>1e26ffabe380c3d0c299</td>\n",
       "      <td>NO9EDSU0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almigrana1</td>\n",
       "      <td>2259ed1d208cca75004d</td>\n",
       "      <td>4XS7R110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quiero95</td>\n",
       "      <td>16194b66fbca0eee</td>\n",
       "      <td>BMZPZLBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doitnow2</td>\n",
       "      <td>fab56cb16f5cd504</td>\n",
       "      <td>19RM3TPZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>quaisha123</td>\n",
       "      <td>ee52380036e56d18fedf</td>\n",
       "      <td>N2C957EO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>7192qween</td>\n",
       "      <td>af145da41167c9823e</td>\n",
       "      <td>OPM4TFXK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>janet35</td>\n",
       "      <td>64e336d210b11e</td>\n",
       "      <td>ARY69F82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>velly</td>\n",
       "      <td>3bf88e62b3</td>\n",
       "      <td>056LFPUW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>almaenid28</td>\n",
       "      <td>992dd60e02852ba4da5a</td>\n",
       "      <td>6R380KEQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Passwords            ciphertext       key\n",
       "0       2428031609  1092675125059b44fa88  ZDBQ7O9F\n",
       "1       4531040045  1e26ffabe380c3d0c299  NO9EDSU0\n",
       "2       almigrana1  2259ed1d208cca75004d  4XS7R110\n",
       "3         quiero95      16194b66fbca0eee  BMZPZLBH\n",
       "4         doitnow2      fab56cb16f5cd504  19RM3TPZ\n",
       "...            ...                   ...       ...\n",
       "119995  quaisha123  ee52380036e56d18fedf  N2C957EO\n",
       "119996   7192qween    af145da41167c9823e  OPM4TFXK\n",
       "119997     janet35        64e336d210b11e  ARY69F82\n",
       "119998       velly            3bf88e62b3  056LFPUW\n",
       "119999  almaenid28  992dd60e02852ba4da5a  6R380KEQ\n",
       "\n",
       "[120000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'].apply(str)\n",
    "df['ciphertext'].apply(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44T02G-FBNYf"
   },
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9b4vwned1-4",
    "outputId": "a955da71-52ac-4881-e8ed-78d398c47ec9"
   },
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level=True)\n",
    "    x_tk.fit_on_texts(x)                 \n",
    "\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    \n",
    "    return pad_sequences(x, maxlen=length, padding=\"post\", truncating=\"post\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdV69c9gd1-5"
   },
   "source": [
    "### Preprocess Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxTxyzCHd1-5",
    "outputId": "3f358e66-7cca-4959-8f96-5b96b818532f"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n"
     ]
    }
   ],
   "source": [
    "preproc_code_sentences, preproc_plaintext_sentences, code_tokenizer, plaintext_tokenizer = preprocess(df['Passwords'], df['ciphertext'])\n",
    "\n",
    "print('Data Preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NlbiDf-d1-6",
    "outputId": "21c9cb2e-025e-4032-e29b-8d5a36a6cd4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 17,  7, 15,  5, 13,  3, 19,  5, 12,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_code_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrK0B3ttd1-6",
    "outputId": "86b2b875-ef69-4f0b-f245-62dbf0d7bb3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRkiK6Qjd1-6",
    "outputId": "a473c0bf-f76d-4689-8884-028a871751b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plaintext_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hk8HcQtEd1-7",
    "outputId": "e734311c-c349-47d9-c726-ff275f434840"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 1,\n",
       " 'f': 2,\n",
       " '0': 3,\n",
       " 'b': 4,\n",
       " '2': 5,\n",
       " '5': 6,\n",
       " '9': 7,\n",
       " 'c': 8,\n",
       " 'a': 9,\n",
       " '3': 10,\n",
       " '4': 11,\n",
       " 'd': 12,\n",
       " '7': 13,\n",
       " '6': 14,\n",
       " '1': 15,\n",
       " '8': 16}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plaintext_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPevgp-id1-7",
    "outputId": "e7085fd4-de9d-4636-a167-3681e52eb0a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 255)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_code_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxFxFP-Bd1-7",
    "outputId": "f2ae4663-bf7d-4992-ebad-54c974e2b78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 510, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_plaintext_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKHZqlXyd1-8"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HnLsrRNZd1-8"
   },
   "outputs": [],
   "source": [
    "from keras.layers import GRU, Input, Dense, TimeDistributed, RNN, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "def simple_model(input_shape, output_sequence_length, code_vocab_size, plaintext_vocab_size):\n",
    "    x = Input(shape=input_shape[1:])   \n",
    "    seq = LSTM(units= 256, return_sequences = True, activation=\"tanh\", name='Layer1')(x)\n",
    "    output = TimeDistributed(Dense(units = plaintext_vocab_size, activation='softmax', name='Layer2'))(seq)\n",
    "    model = Model(inputs = x, outputs = output)\n",
    "    model.compile(optimizer='adam', loss= sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "tmp_x = pad(preproc_code_sentences, preproc_plaintext_sentences.shape[1]) \n",
    "tmp_x = tmp_x.reshape((-1, preproc_plaintext_sentences.shape[-2], 1))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOCnrOcnd1-8",
    "outputId": "e9ed1e68-9923-49c0-fe27-7fc6040b24cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 510, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7],\n",
       "       [17],\n",
       "       [ 7],\n",
       "       [15],\n",
       "       [ 5],\n",
       "       [13],\n",
       "       [ 3],\n",
       "       [19],\n",
       "       [ 5],\n",
       "       [12],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBuB49pZd1-9",
    "outputId": "5e165d21-0165-42bb-c5e2-e9bad83454ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 510, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Layer1 (LSTM)                (None, 510, 256)          264192    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 510, 17)           4369      \n",
      "=================================================================\n",
      "Total params: 268,561\n",
      "Trainable params: 268,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_plaintext_sentences.shape[1],\n",
    "    len(code_tokenizer.word_index)+1,\n",
    "    len(plaintext_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1mw5FFZd1-9",
    "outputId": "fa187ab0-36f6-4793-b770-6e678781cacb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 510, 256])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model.get_layer(name=\"Layer1\").output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGK61DACd1-9",
    "outputId": "6059e2f6-bcf3-4b3a-c4c0-81656b9a336f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1313/1313 [==============================] - 104s 67ms/step - loss: 0.1681 - accuracy: 0.9670 - val_loss: 0.0958 - val_accuracy: 0.9681\n",
      "Epoch 2/15\n",
      "1313/1313 [==============================] - 88s 67ms/step - loss: 0.0956 - accuracy: 0.9682 - val_loss: 0.0952 - val_accuracy: 0.9683\n",
      "Epoch 3/15\n",
      "1313/1313 [==============================] - 88s 67ms/step - loss: 0.0952 - accuracy: 0.9683 - val_loss: 0.0950 - val_accuracy: 0.9684\n",
      "Epoch 4/15\n",
      "1313/1313 [==============================] - 87s 67ms/step - loss: 0.0949 - accuracy: 0.9685 - val_loss: 0.0947 - val_accuracy: 0.9685\n",
      "Epoch 5/15\n",
      "1313/1313 [==============================] - 87s 66ms/step - loss: 0.0944 - accuracy: 0.9686 - val_loss: 0.0944 - val_accuracy: 0.9685\n",
      "Epoch 6/15\n",
      "1313/1313 [==============================] - 87s 66ms/step - loss: 0.0941 - accuracy: 0.9687 - val_loss: 0.0939 - val_accuracy: 0.9687\n",
      "Epoch 7/15\n",
      "1313/1313 [==============================] - 87s 66ms/step - loss: 0.0937 - accuracy: 0.9688 - val_loss: 0.0933 - val_accuracy: 0.9689\n",
      "Epoch 8/15\n",
      "1313/1313 [==============================] - 86s 66ms/step - loss: 0.0931 - accuracy: 0.9689 - val_loss: 0.0930 - val_accuracy: 0.9689\n",
      "Epoch 9/15\n",
      "1313/1313 [==============================] - 87s 66ms/step - loss: 0.0927 - accuracy: 0.9690 - val_loss: 0.0926 - val_accuracy: 0.9690\n",
      "Epoch 10/15\n",
      "1313/1313 [==============================] - 87s 66ms/step - loss: 0.0922 - accuracy: 0.9692 - val_loss: 0.0924 - val_accuracy: 0.9691\n",
      "Epoch 11/15\n",
      "1313/1313 [==============================] - 86s 66ms/step - loss: 0.0919 - accuracy: 0.9693 - val_loss: 0.0921 - val_accuracy: 0.9692\n",
      "Epoch 12/15\n",
      "1313/1313 [==============================] - 86s 66ms/step - loss: 0.0920 - accuracy: 0.9693 - val_loss: 0.0919 - val_accuracy: 0.9692\n",
      "Epoch 13/15\n",
      "1313/1313 [==============================] - 87s 66ms/step - loss: 0.0919 - accuracy: 0.9693 - val_loss: 0.0917 - val_accuracy: 0.9693\n",
      "Epoch 14/15\n",
      "1313/1313 [==============================] - 87s 66ms/step - loss: 0.0915 - accuracy: 0.9694 - val_loss: 0.0916 - val_accuracy: 0.9693\n",
      "Epoch 15/15\n",
      "1313/1313 [==============================] - 87s 67ms/step - loss: 0.0910 - accuracy: 0.9696 - val_loss: 0.0914 - val_accuracy: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf913bfdf0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model.fit(tmp_x, preproc_plaintext_sentences, batch_size=64, epochs=15, validation_split=0.3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PI9Ypxpd1--",
    "outputId": "18741fa3-e00d-469a-88aa-bb6944e808e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f a 9 2 6 2 5 0 5 1 9 9 9 b 2 1 b 9 4 e <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], plaintext_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1JG7ZGkhd1--",
    "outputId": "e27e98ad-a65e-4593-ebdd-302e859ce580"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428031609'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF4h-TUXd1-_"
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "zr9DVkOTd1-_"
   },
   "outputs": [],
   "source": [
    "def simple_model1(input_shape, output_sequence_length, code_vocab_size, plaintext_vocab_size):\n",
    "    x = Input(shape=input_shape[1:])   \n",
    "    seq = GRU(units= 256, return_sequences = True, activation=\"tanh\", name='Layer1')(x)  # output must be batchsize x timesteps x units\n",
    "    output = TimeDistributed(Dense(units = plaintext_vocab_size, activation='softmax', name='Layer2'))(seq)\n",
    "    model = Model(inputs = x, outputs = output)\n",
    "    model.compile(optimizer='adam', loss= sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nv3fRkj7d1-_",
    "outputId": "ac22d596-80eb-4d0e-9cfc-090be796cf81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 510, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Layer1 (GRU)                 (None, 510, 256)          198912    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 510, 17)           4369      \n",
      "=================================================================\n",
      "Total params: 203,281\n",
      "Trainable params: 203,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model1 = simple_model1(\n",
    "    tmp_x.shape,\n",
    "    preproc_plaintext_sentences.shape[1],\n",
    "    len(code_tokenizer.word_index)+1,\n",
    "    len(plaintext_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVg9KJaad1-_",
    "outputId": "4df6502d-ca0c-42df-869e-89859ed38db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1313/1313 [==============================] - 76s 56ms/step - loss: 0.2118 - accuracy: 0.9670 - val_loss: 0.1038 - val_accuracy: 0.9676: 58s - loss: 0.9156 - accuracy: 0.96 - ETA: 58s - loss: 0 - ETA: 55s - loss: 0.7142 - accuracy: 0 - ETA: 54s - loss: 0.6859 - accuracy: 0.9 - ETA: 54s - loss: - ETA: 52s - loss: 0.5721 -  - ETA: 50s - loss: 0.5276 - accuracy: 0.9 - ETA: 50s - loss: 0.5198 - accuracy: - ETA: 50s - loss: 0.5051 - accuracy: 0.965 - ETA: 49s - loss: 0.5028 - accurac - ETA: 49s - loss: 0.4830 - accuracy:  - ETA: 48s - loss: 0.4719 - accura - ETA: 47s - loss: 0.4579 - accuracy: 0. - ETA: 47s - loss: 0.4518 - - ETA: 46s - loss: 0.4279 - accuracy: 0.965 - ETA: 46s - loss: 0.4264 - accuracy: 0.96 - ETA: 45s - loss: 0.4236 - accuracy: 0.9 - ETA: 45s - loss: 0.4193 - accuracy - ETA: 45s - loss: 0.4112 - ETA: 43s - loss: 0.3911 - accuracy - ETA: 42s - loss: 0.3839 - accuracy: 0. - ETA: 42s - loss: 0.3807 - accuracy:  - ETA: 42s - loss: 0.3751 - accuracy: 0. - ETA: 41s - loss: 0.3712 - accuracy: 0.96 - ETA: 41s - loss: 0.3702 - - ETA: 40s - loss: 0.3557 - accuracy: 0.9 - ETA: 39s - loss: 0.3532 - accuracy: 0.96 - ETA: 39s - loss: 0.3515 - accuracy: - ETA: 39s - loss: 0.3467 - accuracy: 0.96 - ET - ETA: 35s - loss: 0.3215 - accuracy: 0 - ETA: 35s - loss: 0.3185 - acc - ETA: 34s - loss: 0.3115 - accura - ETA: 33s - loss: 0.3060 - accuracy: 0.9 - ETA: 32s - loss: 0.3044 - accu - ETA: 31s - loss: 0.2994 - accuracy - ETA: 31s - loss: 0.2962 - accuracy: 0.966 - ETA: 31s - loss: 0.2957 - accur - ETA: 30s - loss: 0.2918 - accuracy: - ETA: 29s - loss: 0.2889 - acc - ETA: 2 - ETA: 25s - - ETA: 22s - l - ETA: 20s - loss: 0 - ETA: 18s - loss: 0.2486 - a - ETA: 17s - loss: 0.2450 - accuracy - ETA: 16s - loss: 0.2431 - accurac - ETA: 15s - loss: 0.2413 - accuracy - ETA: 14s - loss:  - ETA: 12s - loss: 0.2350 - accura - ETA: 12s - loss: 0.2332 - accu - ETA: 11s - loss: 0.2311 - accuracy: 0.96 - ETA:  - ETA: 1s - loss: 0.2142 - accuracy: 0. - ETA: 1s - l\n",
      "Epoch 2/15\n",
      "1313/1313 [==============================] - 74s 56ms/step - loss: 0.1013 - accuracy: 0.9678 - val_loss: 0.0960 - val_accuracy: 0.9682loss: 0.1036 - accuracy:  - ETA: 56s - loss: 0.1036 - accuracy: 0.96 - ETA: 56s - loss: 0.1036 - accuracy: 0.967 - - ETA: 53s - loss: 0.1034 - acc - ETA: 52s - loss: 0. - ETA: 50s - loss: 0.1033 - accur - ET - ETA: 41s - loss: 0.1030 - accuracy: 0 - ETA: 41s - loss: 0.1029 - - ETA: 28s - loss: 0.102 - ETA: 14s - loss: 0.1018 - accuracy - ETA: 8s - loss: - E - ETA - ETA: 3s - loss: 0.1014 - ac - E - ETA: 1s - loss: 0.1013 - accuracy - ETA: 0s - loss: 0.1013 - \n",
      "Epoch 3/15\n",
      "1313/1313 [==============================] - 73s 56ms/step - loss: 0.0961 - accuracy: 0.9682 - val_loss: 0.0955 - val_accuracy: 0.9682TA: 1:00 - loss: 0.0955 - accuracy: 0.96 - ETA: 59s - loss: 0.0 - ETA: 54s - loss: 0.0954 - accuracy:  - ETA: 53s - loss: 0.0954 -  - ETA: 52s - loss: 0.0954 - accuracy: 0.968 - ETA: 52s - loss: 0.0954 -  - ETA: 50s -  - ETA: 44s - loss: 0.0956 - accuracy: 0.968 - ETA: 44s - loss: 0.0956 - accuracy:  - - ETA: 40s - loss: 0.0956 - accuracy:  - ETA: 39s - loss:  - ETA: 37s - los - ETA: 30s - loss: 0.0957 - ac - ETA: 25 - ETA: 22s - loss: 0.0959 - accuracy - ETA: 21s -  - ETA: 1 - ETA:  - ETA: 9s - loss: 0.096 - ETA: 8s - los - ETA: 5s - los - ETA: 0s - loss: 0.0961 - accuracy: 0.96 - ETA: 0s - loss: 0.0961 - accuracy\n",
      "Epoch 4/15\n",
      "1313/1313 [==============================] - 74s 56ms/step - loss: 0.0960 - accuracy: 0.9682 - val_loss: 0.0960 - val_accuracy: 0.9682s: 0.0964 - accuracy: 0.968 - ETA: 57s - loss: 0.0964  - ETA: 56s - loss: 0.0964 - accuracy: - ETA: 40s - loss: 0.0963 - accurac - ETA: 39s - loss: 0.0963 - accuracy: 0.96 - ETA: 39s - loss: 0.0963 - accuracy: 0.968 - ETA: 38s - loss: 0.0963 - accuracy: 0.9 - ETA: 38s - loss: 0.0963 - accu - ETA: 37s - loss: 0.0963 - accuracy: - ETA: 37s - loss: 0.0963 - ac - ETA: 31s - los - ETA: 7s - loss: 0.0960 - accura - ETA: 1s - loss:\n",
      "Epoch 5/15\n",
      "1313/1313 [==============================] - 74s 57ms/step - loss: 0.0952 - accuracy: 0.9683 - val_loss: 0.0951 - val_accuracy: 0.9683 loss: 0.0958 - - ETA: 52s - loss: 0.0953 - acc - ETA: 50 - ETA: 47s - loss: 0.0952 - accuracy: 0. - ETA: 47s - loss: 0.095 - ETA: 46s - loss: 0.0951 - a - ETA: 26s - loss: 0. - ETA: 2 -  - ETA: 17s - loss: 0.095 - ETA: 16s - loss: 0.0951 - a - ETA: 15s - loss: 0.0951 - accuracy: - ETA: \n",
      "Epoch 6/15\n",
      "1313/1313 [==============================] - 73s 56ms/step - loss: 0.0949 - accuracy: 0.9684 - val_loss: 0.0948 - val_accuracy: 0.9684- ETA: 52s - loss: 0.0950  - ETA: 50s - loss: 0.0950 - accuracy: 0.9 - ETA: 50s - loss: 0.0950 - acc - ETA: 24s - loss: 0.0948 - acc -  - ETA: 19s - loss: 0.0948 - accu - ET - ETA: 14s - loss: 0.0948 - accuracy: 0 - ETA: 14s - loss: 0.0948 - accuracy: 0.96 - ETA: 14s - loss: 0.0948 - - ETA: - ETA: 1s - ETA: 0s - loss: 0.0949 - accuracy: 0.96\n",
      "Epoch 7/15\n",
      "1313/1313 [==============================] - 73s 56ms/step - loss: 0.0947 - accuracy: 0.9685 - val_loss: 0.0946 - val_accuracy: 0.9685\n",
      "Epoch 8/15\n",
      "1313/1313 [==============================] - 73s 56ms/step - loss: 0.0945 - accuracy: 0.9685 - val_loss: 0.0946 - val_accuracy: 0.9684\n",
      "Epoch 9/15\n",
      "1313/1313 [==============================] - 74s 56ms/step - loss: 0.0945 - accuracy: 0.9685 - val_loss: 0.0941 - val_accuracy: 0.9686\n",
      "Epoch 10/15\n",
      "1313/1313 [==============================] - 74s 56ms/step - loss: 0.0939 - accuracy: 0.9687 - val_loss: 0.0936 - val_accuracy: 0.9688\n",
      "Epoch 11/15\n",
      "1313/1313 [==============================] - 73s 55ms/step - loss: 0.0934 - accuracy: 0.9689 - val_loss: 0.0936 - val_accuracy: 0.9688\n",
      "Epoch 12/15\n",
      "1313/1313 [==============================] - 74s 56ms/step - loss: 0.0931 - accuracy: 0.9690 - val_loss: 0.0952 - val_accuracy: 0.9685\n",
      "Epoch 13/15\n",
      "1313/1313 [==============================] - 74s 57ms/step - loss: 0.0933 - accuracy: 0.9689 - val_loss: 0.0934 - val_accuracy: 0.9688\n",
      "Epoch 14/15\n",
      "1313/1313 [==============================] - 74s 56ms/step - loss: 0.0928 - accuracy: 0.9690 - val_loss: 0.0932 - val_accuracy: 0.9689\n",
      "Epoch 15/15\n",
      "1313/1313 [==============================] - 74s 56ms/step - loss: 0.0927 - accuracy: 0.9690 - val_loss: 0.0926 - val_accuracy: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c09a670a60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model1.fit(tmp_x, preproc_plaintext_sentences, batch_size=64, epochs=15, validation_split=0.3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sr0zJux1d1-_",
    "outputId": "54ac6118-4a93-4968-f8c8-1dd9a11f76f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f 1 e 1 6 b 3 3 5 3 9 b 9 3 2 3 b 5 4 f <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(logits_to_text(simple_rnn_model1.predict(tmp_x[:1])[0], plaintext_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fFQT3peGUOHg",
    "outputId": "659da06c-0ebb-44cf-ec44-6f90d7fc0379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428031609'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHjZkjOzd1_A"
   },
   "source": [
    "# SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "baVCVerFd1_A"
   },
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN \n",
    "def simple_model2(input_shape, output_sequence_length, code_vocab_size, plaintext_vocab_size):\n",
    "    x = Input(shape=input_shape[1:])      \n",
    "    seq = SimpleRNN(units= 256, return_sequences = True, activation=\"tanh\", name='Layer1')(x)   \n",
    "    output = TimeDistributed(Dense(units = plaintext_vocab_size, activation='softmax', name='Layer2'))(seq)    \n",
    "    model = Model(inputs = x, outputs = output)    \n",
    "    model.compile(optimizer='adam', loss= sparse_categorical_crossentropy, metrics=['accuracy'])    \n",
    "    model.summary()    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yieRDWbzd1_A",
    "outputId": "0db4c447-20c1-4589-f29d-150d755c913c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 510, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Layer1 (SimpleRNN)           (None, 510, 256)          66048     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 510, 17)           4369      \n",
      "=================================================================\n",
      "Total params: 70,417\n",
      "Trainable params: 70,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model2 = simple_model2(\n",
    "    tmp_x.shape,\n",
    "    preproc_plaintext_sentences.shape[1],\n",
    "    len(code_tokenizer.word_index)+1,\n",
    "    len(plaintext_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbr40u5Gd1_A",
    "outputId": "227f6ecf-3795-46ee-85d7-04ced2d0c98b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1313/1313 [==============================] - 402s 303ms/step - loss: 0.2700 - accuracy: 0.9462 - val_loss: 0.1876 - val_accuracy: 0.9665\n",
      "Epoch 2/15\n",
      "1313/1313 [==============================] - 404s 307ms/step - loss: 0.1243 - accuracy: 0.9675 - val_loss: 0.1062 - val_accuracy: 0.9676\n",
      "Epoch 3/15\n",
      "1313/1313 [==============================] - 404s 308ms/step - loss: 0.1049 - accuracy: 0.9677 - val_loss: 0.1018 - val_accuracy: 0.9678\n",
      "Epoch 4/15\n",
      "1313/1313 [==============================] - 398s 303ms/step - loss: 0.1009 - accuracy: 0.9680 - val_loss: 0.0992 - val_accuracy: 0.9679\n",
      "Epoch 5/15\n",
      "1313/1313 [==============================] - 397s 303ms/step - loss: 0.0988 - accuracy: 0.9680 - val_loss: 0.0962 - val_accuracy: 0.9682\n",
      "Epoch 6/15\n",
      "1313/1313 [==============================] - 403s 307ms/step - loss: 0.0978 - accuracy: 0.9681 - val_loss: 0.0977 - val_accuracy: 0.9683\n",
      "Epoch 7/15\n",
      "1313/1313 [==============================] - 399s 304ms/step - loss: 0.0966 - accuracy: 0.9683 - val_loss: 0.0959 - val_accuracy: 0.9684\n",
      "Epoch 8/15\n",
      "1313/1313 [==============================] - 399s 304ms/step - loss: 0.1222 - accuracy: 0.9658 - val_loss: 0.1066 - val_accuracy: 0.9672\n",
      "Epoch 9/15\n",
      "1313/1313 [==============================] - 397s 302ms/step - loss: 0.1060 - accuracy: 0.9673 - val_loss: 0.1040 - val_accuracy: 0.9675\n",
      "Epoch 10/15\n",
      "1313/1313 [==============================] - 397s 302ms/step - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.0994 - val_accuracy: 0.9679\n",
      "Epoch 11/15\n",
      "1313/1313 [==============================] - 403s 307ms/step - loss: 0.1024 - accuracy: 0.9678 - val_loss: 0.1007 - val_accuracy: 0.9678\n",
      "Epoch 12/15\n",
      "1313/1313 [==============================] - 398s 303ms/step - loss: 0.1042 - accuracy: 0.9677 - val_loss: 0.1041 - val_accuracy: 0.9677\n",
      "Epoch 13/15\n",
      "1313/1313 [==============================] - 403s 307ms/step - loss: 0.1039 - accuracy: 0.9678 - val_loss: 0.1037 - val_accuracy: 0.9678\n",
      "Epoch 14/15\n",
      "1313/1313 [==============================] - 397s 302ms/step - loss: 0.1034 - accuracy: 0.9678 - val_loss: 0.1042 - val_accuracy: 0.9677\n",
      "Epoch 15/15\n",
      "1313/1313 [==============================] - 394s 300ms/step - loss: 0.1045 - accuracy: 0.9678 - val_loss: 0.1037 - val_accuracy: 0.9677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c0c708a520>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model2.fit(tmp_x, preproc_plaintext_sentences, batch_size=64, epochs=15, validation_split=0.3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYddd_hgd1_A",
    "outputId": "e20b6799-3560-4480-a15d-a356d76bd72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f 1 e 5 d 5 d 5 d 5 7 d 5 d d d <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(logits_to_text(simple_rnn_model2.predict(tmp_x[:1])[0], plaintext_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FOpT4aQHUsbA",
    "outputId": "6a111a74-a67e-42bb-eaa0-1c0b7f77c749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428031609'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deciphering Code with Character-Level RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
