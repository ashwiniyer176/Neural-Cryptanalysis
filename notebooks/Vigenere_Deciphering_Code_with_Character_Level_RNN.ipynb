{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GSMwZnsd1-u"
   },
   "source": [
    "# Deciphering Code with Character-Level RNN\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOHhumaPBdAk"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passwords</th>\n",
       "      <th>ciphertext</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2428031609</td>\n",
       "      <td>yux6njoswz</td>\n",
       "      <td>6058xqxw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4531040045</td>\n",
       "      <td>x4s5cmclx4</td>\n",
       "      <td>39zemsmv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almigrana1</td>\n",
       "      <td>jjfflk9ijz</td>\n",
       "      <td>j837f395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quiero95</td>\n",
       "      <td>2h5e32dn</td>\n",
       "      <td>mxxamoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doitnow2</td>\n",
       "      <td>luibyzc7</td>\n",
       "      <td>igasllqf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>dime168</td>\n",
       "      <td>es02coa</td>\n",
       "      <td>bkoylscm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>!l0v3k3v!n</td>\n",
       "      <td>!90iecvx!q</td>\n",
       "      <td>yaxl22cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>9870tmf05</td>\n",
       "      <td>7pf8j4ad3</td>\n",
       "      <td>8rii0s5n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>CAMILA</td>\n",
       "      <td>wqj7jx</td>\n",
       "      <td>uq7z8xdh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>caren14</td>\n",
       "      <td>v6s6mcd</td>\n",
       "      <td>t6b29lj4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Passwords  ciphertext       key\n",
       "0       2428031609  yux6njoswz  6058xqxw\n",
       "1       4531040045  x4s5cmclx4  39zemsmv\n",
       "2       almigrana1  jjfflk9ijz  j837f395\n",
       "3         quiero95    2h5e32dn  mxxamoes\n",
       "4         doitnow2    luibyzc7  igasllqf\n",
       "...            ...         ...       ...\n",
       "199995     dime168     es02coa  bkoylscm\n",
       "199996  !l0v3k3v!n  !90iecvx!q  yaxl22cd\n",
       "199997   9870tmf05   7pf8j4ad3  8rii0s5n\n",
       "199998      CAMILA      wqj7jx  uq7z8xdh\n",
       "199999     caren14     v6s6mcd  t6b29lj4\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/Vigenere.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()[:120000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passwords</th>\n",
       "      <th>ciphertext</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2428031609</td>\n",
       "      <td>yux6njoswz</td>\n",
       "      <td>6058xqxw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4531040045</td>\n",
       "      <td>x4s5cmclx4</td>\n",
       "      <td>39zemsmv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almigrana1</td>\n",
       "      <td>jjfflk9ijz</td>\n",
       "      <td>j837f395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quiero95</td>\n",
       "      <td>2h5e32dn</td>\n",
       "      <td>mxxamoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doitnow2</td>\n",
       "      <td>luibyzc7</td>\n",
       "      <td>igasllqf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>quaisha123</td>\n",
       "      <td>euxtk9c4q3</td>\n",
       "      <td>yaxl22cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>7192qween</td>\n",
       "      <td>p1lvt7ur5</td>\n",
       "      <td>sam3dlqn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>janet35</td>\n",
       "      <td>sd4eaou</td>\n",
       "      <td>jdrarvzx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>velly</td>\n",
       "      <td>j5073</td>\n",
       "      <td>y1pwfvfj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>almaenid28</td>\n",
       "      <td>irmspyyiae</td>\n",
       "      <td>igasllqf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Passwords  ciphertext       key\n",
       "0       2428031609  yux6njoswz  6058xqxw\n",
       "1       4531040045  x4s5cmclx4  39zemsmv\n",
       "2       almigrana1  jjfflk9ijz  j837f395\n",
       "3         quiero95    2h5e32dn  mxxamoes\n",
       "4         doitnow2    luibyzc7  igasllqf\n",
       "...            ...         ...       ...\n",
       "119995  quaisha123  euxtk9c4q3  yaxl22cd\n",
       "119996   7192qween   p1lvt7ur5  sam3dlqn\n",
       "119997     janet35     sd4eaou  jdrarvzx\n",
       "119998       velly       j5073  y1pwfvfj\n",
       "119999  almaenid28  irmspyyiae  igasllqf\n",
       "\n",
       "[120000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'].apply(str)\n",
    "df['ciphertext'].apply(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44T02G-FBNYf"
   },
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9b4vwned1-4",
    "outputId": "a955da71-52ac-4881-e8ed-78d398c47ec9"
   },
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level=True)\n",
    "    x_tk.fit_on_texts(x)                 \n",
    "\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    \n",
    "    return pad_sequences(x, maxlen=length, padding=\"post\", truncating=\"post\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdV69c9gd1-5"
   },
   "source": [
    "### Preprocess Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxTxyzCHd1-5",
    "outputId": "3f358e66-7cca-4959-8f96-5b96b818532f"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n"
     ]
    }
   ],
   "source": [
    "preproc_code_sentences, preproc_plaintext_sentences, code_tokenizer, plaintext_tokenizer = preprocess(df['Passwords'], df['ciphertext'])\n",
    "\n",
    "print('Data Preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NlbiDf-d1-6",
    "outputId": "21c9cb2e-025e-4032-e29b-8d5a36a6cd4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 17,  7, 15,  5, 13,  3, 19,  5, 12,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_code_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrK0B3ttd1-6",
    "outputId": "86b2b875-ef69-4f0b-f245-62dbf0d7bb3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRkiK6Qjd1-6",
    "outputId": "a473c0bf-f76d-4689-8884-028a871751b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plaintext_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hk8HcQtEd1-7",
    "outputId": "e734311c-c349-47d9-c726-ff275f434840"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 1,\n",
       " 'o': 2,\n",
       " 'g': 3,\n",
       " 'a': 4,\n",
       " 'e': 5,\n",
       " 'l': 6,\n",
       " 'u': 7,\n",
       " 'y': 8,\n",
       " '5': 9,\n",
       " '9': 10,\n",
       " 'h': 11,\n",
       " 'b': 12,\n",
       " 'n': 13,\n",
       " '8': 14,\n",
       " 'i': 15,\n",
       " '3': 16,\n",
       " 'r': 17,\n",
       " '1': 18,\n",
       " '4': 19,\n",
       " 'd': 20,\n",
       " 'm': 21,\n",
       " 'j': 22,\n",
       " 'c': 23,\n",
       " 'z': 24,\n",
       " '0': 25,\n",
       " 'f': 26,\n",
       " '6': 27,\n",
       " 'x': 28,\n",
       " 'q': 29,\n",
       " 'p': 30,\n",
       " 's': 31,\n",
       " '2': 32,\n",
       " 't': 33,\n",
       " '7': 34,\n",
       " 'v': 35,\n",
       " 'w': 36,\n",
       " '.': 37,\n",
       " '_': 38,\n",
       " '!': 39,\n",
       " '-': 40,\n",
       " '*': 41,\n",
       " '@': 42,\n",
       " ' ': 43,\n",
       " '/': 44,\n",
       " '#': 45,\n",
       " 'à': 46,\n",
       " '¸': 47,\n",
       " '$': 48,\n",
       " '+': 49,\n",
       " ',': 50,\n",
       " '&': 51,\n",
       " '=': 52,\n",
       " '\\\\': 53,\n",
       " ')': 54,\n",
       " '(': 55,\n",
       " '?': 56,\n",
       " ';': 57,\n",
       " \"'\": 58,\n",
       " '<': 59,\n",
       " ']': 60,\n",
       " '\"': 61,\n",
       " '%': 62,\n",
       " '[': 63,\n",
       " ':': 64,\n",
       " '~': 65,\n",
       " 'ã': 66,\n",
       " '¹': 67,\n",
       " '`': 68,\n",
       " '>': 69,\n",
       " '^': 70,\n",
       " '\\x9f': 71,\n",
       " '±': 72,\n",
       " '\\x99': 73,\n",
       " '\\x88': 74,\n",
       " '£': 75,\n",
       " '\\x85': 76,\n",
       " '·': 77,\n",
       " '\\x84': 78,\n",
       " '°': 79,\n",
       " '\\x97': 80,\n",
       " '|': 81,\n",
       " '\\xa0': 82,\n",
       " '\\x81': 83,\n",
       " '\\x95': 84,\n",
       " '³': 85,\n",
       " '²': 86,\n",
       " '×': 87,\n",
       " 'â': 88,\n",
       " '\\x96': 89,\n",
       " '{': 90,\n",
       " '\\x9e': 91,\n",
       " '¼': 92,\n",
       " '\\x89': 93,\n",
       " '§': 94,\n",
       " 'ä': 95,\n",
       " '¤': 96,\n",
       " '¶': 97,\n",
       " '¥': 98,\n",
       " 'ª': 99,\n",
       " '}': 100,\n",
       " '´': 101,\n",
       " '©': 102,\n",
       " '\\x80': 103,\n",
       " '\\x91': 104,\n",
       " 'î': 105,\n",
       " '\\xad': 106,\n",
       " '\\x8c': 107,\n",
       " '¢': 108,\n",
       " '\\x94': 109,\n",
       " 'ï': 110,\n",
       " '¡': 111,\n",
       " '«': 112,\n",
       " '\\x93': 113,\n",
       " '\\x98': 114,\n",
       " 'µ': 115,\n",
       " '\\x87': 116,\n",
       " '\\x9c': 117,\n",
       " '\\x83': 118,\n",
       " '\\x9a': 119,\n",
       " '¨': 120,\n",
       " 'å': 121,\n",
       " 'ö': 122,\n",
       " '\\n': 123,\n",
       " '\\x86': 124,\n",
       " '\\x8e': 125,\n",
       " '\\x8d': 126,\n",
       " '\\x8a': 127,\n",
       " 'á': 128,\n",
       " '»': 129,\n",
       " '\\x8b': 130,\n",
       " '\\x9b': 131,\n",
       " '\\x92': 132,\n",
       " '\\x9d': 133,\n",
       " '\\x82': 134,\n",
       " '¿': 135}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plaintext_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPevgp-id1-7",
    "outputId": "e7085fd4-de9d-4636-a167-3681e52eb0a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 255)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_code_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxFxFP-Bd1-7",
    "outputId": "f2ae4663-bf7d-4992-ebad-54c974e2b78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 255, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_plaintext_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKHZqlXyd1-8"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HnLsrRNZd1-8"
   },
   "outputs": [],
   "source": [
    "from keras.layers import GRU, Input, Dense, TimeDistributed, RNN, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "def simple_model(input_shape, output_sequence_length, code_vocab_size, plaintext_vocab_size):\n",
    "    x = Input(shape=input_shape[1:])   \n",
    "    seq = LSTM(units= 128, return_sequences = True, activation=\"tanh\", name='Layer1')(x)\n",
    "    output = TimeDistributed(Dense(units = plaintext_vocab_size, activation='softmax', name='Layer2'))(seq)\n",
    "    model = Model(inputs = x, outputs = output)\n",
    "    model.compile(optimizer='adam', loss= sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "tmp_x = pad(preproc_code_sentences, preproc_plaintext_sentences.shape[1]) \n",
    "tmp_x = tmp_x.reshape((-1, preproc_plaintext_sentences.shape[-2], 1))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOCnrOcnd1-8",
    "outputId": "e9ed1e68-9923-49c0-fe27-7fc6040b24cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 255, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBuB49pZd1-9",
    "outputId": "5e165d21-0165-42bb-c5e2-e9bad83454ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 255, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Layer1 (LSTM)                (None, 255, 128)          66560     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 255, 136)          17544     \n",
      "=================================================================\n",
      "Total params: 84,104\n",
      "Trainable params: 84,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_plaintext_sentences.shape[1],\n",
    "    len(code_tokenizer.word_index)+1,\n",
    "    len(plaintext_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1mw5FFZd1-9",
    "outputId": "fa187ab0-36f6-4793-b770-6e678781cacb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 255, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model.get_layer(name=\"Layer1\").output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGK61DACd1-9",
    "outputId": "6059e2f6-bcf3-4b3a-c4c0-81656b9a336f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1313/1313 [==============================] - 53s 28ms/step - loss: 0.3595 - accuracy: 0.9640 - val_loss: 0.1261 - val_accuracy: 0.9667\n",
      "Epoch 2/15\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.1252 - accuracy: 0.9668 - val_loss: 0.1241 - val_accuracy: 0.9669\n",
      "Epoch 3/15\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.1236 - accuracy: 0.9669 - val_loss: 0.1231 - val_accuracy: 0.9670\n",
      "Epoch 4/15\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.1229 - accuracy: 0.9670 - val_loss: 0.1223 - val_accuracy: 0.9672\n",
      "Epoch 5/15\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.1221 - accuracy: 0.9672 - val_loss: 0.1217 - val_accuracy: 0.9672\n",
      "Epoch 6/15\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.1218 - accuracy: 0.9672 - val_loss: 0.1213 - val_accuracy: 0.9673\n",
      "Epoch 7/15\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.1209 - accuracy: 0.9674 - val_loss: 0.1207 - val_accuracy: 0.9675\n",
      "Epoch 8/15\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.1205 - accuracy: 0.9675 - val_loss: 0.1203 - val_accuracy: 0.9676\n",
      "Epoch 9/15\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.1200 - accuracy: 0.9676 - val_loss: 0.1198 - val_accuracy: 0.9675\n",
      "Epoch 10/15\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.1194 - accuracy: 0.9677 - val_loss: 0.1192 - val_accuracy: 0.9676\n",
      "Epoch 11/15\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.1188 - accuracy: 0.9678 - val_loss: 0.1189 - val_accuracy: 0.9677\n",
      "Epoch 12/15\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.1183 - accuracy: 0.9679 - val_loss: 0.1183 - val_accuracy: 0.9678\n",
      "Epoch 13/15\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.1180 - accuracy: 0.9679 - val_loss: 0.1178 - val_accuracy: 0.9679\n",
      "Epoch 14/15\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.1175 - accuracy: 0.9680 - val_loss: 0.1174 - val_accuracy: 0.9679\n",
      "Epoch 15/15\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.1172 - accuracy: 0.9680 - val_loss: 0.1170 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a4aeee9580>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model.fit(tmp_x, preproc_plaintext_sentences, batch_size=64, epochs=15, validation_split=0.3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PI9Ypxpd1--",
    "outputId": "18741fa3-e00d-469a-88aa-bb6944e808e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 4 v w 1 j h j b f <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], plaintext_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1JG7ZGkhd1--",
    "outputId": "e27e98ad-a65e-4593-ebdd-302e859ce580"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428031609'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF4h-TUXd1-_"
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zr9DVkOTd1-_"
   },
   "outputs": [],
   "source": [
    "def simple_model1(input_shape, output_sequence_length, code_vocab_size, plaintext_vocab_size):\n",
    "    x = Input(shape=input_shape[1:])   \n",
    "    seq = GRU(units= 128, return_sequences = True, activation=\"tanh\", name='Layer1')(x)  # output must be batchsize x timesteps x units\n",
    "    output = TimeDistributed(Dense(units = plaintext_vocab_size, activation='softmax', name='Layer2'))(seq)\n",
    "    model = Model(inputs = x, outputs = output)\n",
    "    model.compile(optimizer='adam', loss= sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nv3fRkj7d1-_",
    "outputId": "ac22d596-80eb-4d0e-9cfc-090be796cf81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 255, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Layer1 (GRU)                 (None, 255, 128)          50304     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 255, 136)          17544     \n",
      "=================================================================\n",
      "Total params: 67,848\n",
      "Trainable params: 67,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model1 = simple_model1(\n",
    "    tmp_x.shape,\n",
    "    preproc_plaintext_sentences.shape[1],\n",
    "    len(code_tokenizer.word_index)+1,\n",
    "    len(plaintext_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVg9KJaad1-_",
    "outputId": "4df6502d-ca0c-42df-869e-89859ed38db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1313/1313 [==============================] - 39s 28ms/step - loss: 0.4419 - accuracy: 0.9655 - val_loss: 0.1254 - val_accuracy: 0.9667\n",
      "Epoch 2/15\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.1245 - accuracy: 0.9668 - val_loss: 0.1234 - val_accuracy: 0.9669s: 0\n",
      "Epoch 3/15\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.1228 - accuracy: 0.9671 - val_loss: 0.1225 - val_accuracy: 0.9671\n",
      "Epoch 4/15\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.1220 - accuracy: 0.9672 - val_loss: 0.1218 - val_accuracy: 0.9673\n",
      "Epoch 5/15\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.1215 - accuracy: 0.9673 - val_loss: 0.1212 - val_accuracy: 0.9673\n",
      "Epoch 6/15\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.1206 - accuracy: 0.9675 - val_loss: 0.1207 - val_accuracy: 0.9674\n",
      "Epoch 7/15\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.1203 - accuracy: 0.9675 - val_loss: 0.1201 - val_accuracy: 0.9675\n",
      "Epoch 8/15\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.1197 - accuracy: 0.9676 - val_loss: 0.1196 - val_accuracy: 0.9677\n",
      "Epoch 9/15\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.1190 - accuracy: 0.9677 - val_loss: 0.1191 - val_accuracy: 0.9677\n",
      "Epoch 10/15\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.1186 - accuracy: 0.9678 - val_loss: 0.1184 - val_accuracy: 0.9679\n",
      "Epoch 11/15\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.1182 - accuracy: 0.9679 - val_loss: 0.1181 - val_accuracy: 0.9679\n",
      "Epoch 12/15\n",
      "1313/1313 [==============================] - 34s 26ms/step - loss: 0.1177 - accuracy: 0.9680 - val_loss: 0.1175 - val_accuracy: 0.9680\n",
      "Epoch 13/15\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.1170 - accuracy: 0.9681 - val_loss: 0.1175 - val_accuracy: 0.9679\n",
      "Epoch 14/15\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.1171 - accuracy: 0.9680 - val_loss: 0.1168 - val_accuracy: 0.9680\n",
      "Epoch 15/15\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.1162 - accuracy: 0.9682 - val_loss: 0.1164 - val_accuracy: 0.9681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a58391ef10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model1.fit(tmp_x, preproc_plaintext_sentences, batch_size=64, epochs=15, validation_split=0.3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sr0zJux1d1-_",
    "outputId": "54ac6118-4a93-4968-f8c8-1dd9a11f76f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 8 v t c k g k b 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(logits_to_text(simple_rnn_model1.predict(tmp_x[:1])[0], plaintext_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fFQT3peGUOHg",
    "outputId": "659da06c-0ebb-44cf-ec44-6f90d7fc0379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428031609'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHjZkjOzd1_A"
   },
   "source": [
    "# SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "baVCVerFd1_A"
   },
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN \n",
    "def simple_model2(input_shape, output_sequence_length, code_vocab_size, plaintext_vocab_size):\n",
    "    x = Input(shape=input_shape[1:])      \n",
    "    seq = SimpleRNN(units= 128, return_sequences = True, activation=\"tanh\", name='Layer1')(x)   \n",
    "    output = TimeDistributed(Dense(units = plaintext_vocab_size, activation='softmax', name='Layer2'))(seq)    \n",
    "    model = Model(inputs = x, outputs = output)    \n",
    "    model.compile(optimizer='adam', loss= sparse_categorical_crossentropy, metrics=['accuracy'])    \n",
    "    model.summary()    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yieRDWbzd1_A",
    "outputId": "0db4c447-20c1-4589-f29d-150d755c913c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 255, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Layer1 (SimpleRNN)           (None, 255, 128)          16640     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 255, 136)          17544     \n",
      "=================================================================\n",
      "Total params: 34,184\n",
      "Trainable params: 34,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model2 = simple_model2(\n",
    "    tmp_x.shape,\n",
    "    preproc_plaintext_sentences.shape[1],\n",
    "    len(code_tokenizer.word_index)+1,\n",
    "    len(plaintext_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbr40u5Gd1_A",
    "outputId": "227f6ecf-3795-46ee-85d7-04ced2d0c98b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1313/1313 [==============================] - 195s 146ms/step - loss: 0.3202 - accuracy: 0.9517 - val_loss: 0.1256 - val_accuracy: 0.9668\n",
      "Epoch 2/15\n",
      "1313/1313 [==============================] - 190s 145ms/step - loss: 0.1247 - accuracy: 0.9668 - val_loss: 0.1239 - val_accuracy: 0.9670\n",
      "Epoch 3/15\n",
      "1313/1313 [==============================] - 192s 146ms/step - loss: 0.1233 - accuracy: 0.9670 - val_loss: 0.1229 - val_accuracy: 0.9670\n",
      "Epoch 4/15\n",
      "1313/1313 [==============================] - 192s 146ms/step - loss: 0.1225 - accuracy: 0.9671 - val_loss: 0.1223 - val_accuracy: 0.9671\n",
      "Epoch 5/15\n",
      "1313/1313 [==============================] - 198s 151ms/step - loss: 0.1219 - accuracy: 0.9672 - val_loss: 0.1216 - val_accuracy: 0.9672\n",
      "Epoch 6/15\n",
      "1313/1313 [==============================] - 202s 154ms/step - loss: 0.1215 - accuracy: 0.9672 - val_loss: 0.1211 - val_accuracy: 0.9673\n",
      "Epoch 7/15\n",
      "1313/1313 [==============================] - 206s 157ms/step - loss: 0.1206 - accuracy: 0.9674 - val_loss: 0.1204 - val_accuracy: 0.9675\n",
      "Epoch 8/15\n",
      "1313/1313 [==============================] - 200s 152ms/step - loss: 0.1200 - accuracy: 0.9675 - val_loss: 0.1198 - val_accuracy: 0.9675\n",
      "Epoch 9/15\n",
      "1313/1313 [==============================] - 203s 154ms/step - loss: 0.1194 - accuracy: 0.9676 - val_loss: 0.1190 - val_accuracy: 0.9677\n",
      "Epoch 10/15\n",
      "1313/1313 [==============================] - 201s 153ms/step - loss: 0.1186 - accuracy: 0.9678 - val_loss: 0.1185 - val_accuracy: 0.9677\n",
      "Epoch 11/15\n",
      "1313/1313 [==============================] - 201s 153ms/step - loss: 0.1182 - accuracy: 0.9678 - val_loss: 0.1180 - val_accuracy: 0.9679\n",
      "Epoch 12/15\n",
      "1313/1313 [==============================] - 200s 152ms/step - loss: 0.1178 - accuracy: 0.9678 - val_loss: 0.1177 - val_accuracy: 0.9679\n",
      "Epoch 13/15\n",
      "1313/1313 [==============================] - 202s 154ms/step - loss: 0.1174 - accuracy: 0.9679 - val_loss: 0.1173 - val_accuracy: 0.9680\n",
      "Epoch 14/15\n",
      "1313/1313 [==============================] - 198s 151ms/step - loss: 0.1168 - accuracy: 0.9680 - val_loss: 0.1169 - val_accuracy: 0.9680\n",
      "Epoch 15/15\n",
      "1313/1313 [==============================] - 201s 153ms/step - loss: 0.1166 - accuracy: 0.9680 - val_loss: 0.1166 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5b2f10ca0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model2.fit(tmp_x, preproc_plaintext_sentences, batch_size=64, epochs=15, validation_split=0.3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYddd_hgd1_A",
    "outputId": "e20b6799-3560-4480-a15d-a356d76bd72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 4 p w 0 q i j b 4 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(logits_to_text(simple_rnn_model2.predict(tmp_x[:1])[0], plaintext_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FOpT4aQHUsbA",
    "outputId": "6a111a74-a67e-42bb-eaa0-1c0b7f77c749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428031609'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Passwords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deciphering Code with Character-Level RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
